{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "import helper_module\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50, VGG16, VGG19, DenseNet121, MobileNetV3Large, EfficientNetV2S\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers, Model\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.image import ssim\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print('GPU is available')\n",
    "else:\n",
    "    print('GPU is not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairing_df =helper_module.read_csv_to_df('dataset/train.csv')\n",
    "test_candidates_df = helper_module.read_csv_to_df('dataset/test_candidates.csv')\n",
    "archive_images_df = helper_module.read_csv_to_df('archive/votes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data generator for training\n",
    "# Additional data augmentation may be added here if desired\n",
    "\n",
    "train_datagen = ImageDataGenerator (\n",
    "    rescale=1./255,         # Rescale pixel values to [0, 1]\n",
    "    rotation_range=0,      # Randomly rotate images by up to 20 degrees\n",
    "    width_shift_range=0.2,  # Randomly shift image width by up to 20%\n",
    "    height_shift_range=0.2, # Randomly shift image height by up to 20%\n",
    "    shear_range=0.2,        # Shear transformations\n",
    "    zoom_range=0.0,         # Randomly zoom in on images by up to 20%\n",
    "    horizontal_flip=False,   # Randomly flip images horizontally\n",
    "    fill_mode='nearest',    # Fill mode for newly created pixels\n",
    "    channel_shift_range=0.2, #Determines the range of the color channel offset\n",
    "    brightness_range=[0.5, 1.5],  # Random brightness\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Gaussian noise function\n",
    "def add_gaussian_noise(image, sigma=25):\n",
    "    row, col, ch = image.shape\n",
    "    mean = 0\n",
    "    gauss = np.random.normal(mean, sigma, (row, col, ch))\n",
    "    noisy = np.clip(image + gauss, 0, 255)\n",
    "    return noisy.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add salt and pepper noise function\n",
    "def add_salt_and_pepper_noise(image, prob=0.01):\n",
    "    \n",
    "    # Create a copy of the image\n",
    "    noisy = np.copy(image)\n",
    "    \n",
    "    # Number of pixels to contaminate with salt and pepper noise\n",
    "    total_pixels = image.size\n",
    "    num_salt = np.ceil(prob * total_pixels * 0.5)\n",
    "    num_pepper = np.ceil(prob * total_pixels * 0.5)\n",
    "\n",
    "    # Add Salt noise\n",
    "    salt_coords = [np.random.randint(0, i-1, int(num_salt)) for i in image.shape]\n",
    "    noisy[salt_coords[0], salt_coords[1], :] = 255\n",
    "\n",
    "    # Add Pepper noise\n",
    "    pepper_coords = [np.random.randint(0, i-1, int(num_pepper)) for i in image.shape]\n",
    "    noisy[pepper_coords[0], pepper_coords[1], :] = 0\n",
    "\n",
    "    return noisy.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to process the input image\n",
    "\n",
    "def load_and_preprocess_image(image_path, target_size=(224,224), random_transform=False, noise_type=None):\n",
    "    # Open the image using Pillow (PIL)\n",
    "    # Pillow is a popular Python image processing library that allows you to open, \n",
    "    # edit, save, and work with a variety of image file formats in Python programs\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "\n",
    "    img = img.resize(target_size)\n",
    "\n",
    "    # Convert the image pixels to a numpy array\n",
    "    img = img_to_array(img, dtype='uint8')\n",
    "\n",
    "\n",
    "    if random_transform:\n",
    "        img = train_datagen.random_transform(img)\n",
    "\n",
    "\n",
    "    # Add Gaussian noise if add_noise is True\n",
    "    if noise_type == 'gaussian':\n",
    "        img = add_gaussian_noise(img)\n",
    "\n",
    "    if noise_type == 'salt_and_pepper':\n",
    "        img= add_salt_and_pepper_noise(img)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_train_valid_dataset(random_transform, left_noise_type=None,right_noise_type=None, num_right_images=20):\n",
    "    # Create a list to store the dataset\n",
    "    dataset = []\n",
    "\n",
    "    # Iterate through the rows of the CSV file and load/preprocess the images\n",
    "    # process each image in the left and right\n",
    "    for index, row in train_pairing_df.iterrows():\n",
    "        left_image = load_and_preprocess_image(f\"dataset/train/left/{row['left']}.jpg\", random_transform=random_transform,noise_type=left_noise_type)\n",
    "\n",
    "        # Load and preprocess similar image\n",
    "        similar_image = load_and_preprocess_image(f\"dataset/train/right/{row['right']}.jpg\", random_transform=random_transform,noise_type=right_noise_type)\n",
    "\n",
    "        # Load and preprocess additional dissimilar images\n",
    "        right_images = [similar_image] # put similar image at index 0\n",
    "\n",
    "        for i in range(num_right_images-1):\n",
    "            # random select image\n",
    "            right_idx = random.randint(0, len(train_pairing_df) - 1)\n",
    "\n",
    "            # Ensure the right right image is different from the similar image\n",
    "            while right_idx == index:\n",
    "                right_idx = random.randint(0, len(train_pairing_df) - 1)\n",
    "\n",
    "            right_image = load_and_preprocess_image(f\"dataset/train/right/{train_pairing_df.iloc[right_idx]['right']}.jpg\", random_transform=random_transform,noise_type=right_noise_type)\n",
    "            right_images.append(right_image)\n",
    "\n",
    "        # Create a data entry containing the left image, list of right images, and the index of the similar image\n",
    "        data_entry = [left_image, right_images]\n",
    "        dataset.append(data_entry)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_train_valid_dataset_archive(random_transform,left_noise_type=None,right_noise_type=None, num_right_images=20):\n",
    "    # Create lists to store paired left and right images\n",
    "    image_pairs_with_label = []\n",
    "\n",
    "    # Define the directory path where your images are located\n",
    "    left_image_directory = 'archive/left/left/'  # Update with the correct directory path\n",
    "    right_image_directory = 'archive/right/right/'  # Update with the correct directory path\n",
    "\n",
    "    # Define the range for generating random indices\n",
    "    min_idx = 1\n",
    "    max_idx = 6015\n",
    "\n",
    "    # Iterate through the rows of the CSV file and load/preprocess the images\n",
    "    for index, row in archive_images_df.iterrows():\n",
    "        # Generate the filename based on the index (e.g., '00000.jpg', '00001.jpg', etc.)\n",
    "        # start from 00000.jpg\n",
    "        image_filename = f\"{index + 1:05d}.jpg\"\n",
    "\n",
    "        # Construct the full paths to the left and right images\n",
    "        left_image_path = os.path.join(left_image_directory, image_filename)\n",
    "        right_image_path = os.path.join(right_image_directory, image_filename)\n",
    "\n",
    "        # Check if both image files exist\n",
    "        if os.path.exists(left_image_path) and os.path.exists(right_image_path) and row['wins']>row['fails']:\n",
    "            # Load and preprocess the left image\n",
    "            left_image = load_and_preprocess_image(left_image_path, random_transform=random_transform,noise_type=left_noise_type)\n",
    "\n",
    "            # Load and preprocess the right image\n",
    "            right_image = load_and_preprocess_image(right_image_path, random_transform=random_transform,noise_type=right_noise_type)\n",
    "\n",
    "            # Create a pair with left image and a list of right images\n",
    "            image_pair_with_label = [left_image, [right_image]]\n",
    "\n",
    "            # Add random dissimilar right images to the list\n",
    "            for _ in range(num_right_images - 1):  # Subtract 1 to account for the similar right image\n",
    "                random_idx = random.randint(min_idx, max_idx)\n",
    "                while random_idx == index + 1:  # Ensure the dissimilar image is not the same as the left image\n",
    "                    random_idx = random.randint(min_idx, max_idx)\n",
    "                dissimilar_image_filename = f\"{random_idx:05d}.jpg\"\n",
    "                dissimilar_image_path = os.path.join(right_image_directory, dissimilar_image_filename)\n",
    "                dissimilar_image = load_and_preprocess_image(dissimilar_image_path, random_transform=random_transform,noise_type=right_noise_type)\n",
    "                image_pair_with_label[1].append(dissimilar_image)\n",
    "\n",
    "            image_pairs_with_label.append(image_pair_with_label)\n",
    "        else:\n",
    "            print(f\"Image files not found for index {index + 1}: {left_image_path}, {right_image_path}\")\n",
    "\n",
    "\n",
    "    return image_pairs_with_label\n",
    "\n",
    "# total 21 image [left[right1,right2]]\n",
    "def display_image_pair(image_pair):\n",
    "    left_image, right_images = image_pair\n",
    "    num_right_images = len(right_images)\n",
    "    \n",
    "    max_images_per_row = 10  # Maximum number of images to display in a single row\n",
    "\n",
    "    num_rows = (num_right_images - 1) // max_images_per_row + 1  # Calculate the number of rows\n",
    "\n",
    "    plt.figure(figsize=(15, 5 * num_rows))\n",
    "\n",
    "    for i in range(num_rows):\n",
    "        start_idx = i * max_images_per_row\n",
    "        end_idx = min((i + 1) * max_images_per_row, num_right_images)\n",
    "        \n",
    "        row_right_images = right_images[start_idx:end_idx]\n",
    "\n",
    "        plt.subplot(num_rows, max_images_per_row + 1, i * (max_images_per_row + 1) + 1)\n",
    "        plt.imshow(left_image)\n",
    "        plt.title(\"Left Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        for j, right_image in enumerate(row_right_images):\n",
    "            plt.subplot(num_rows, max_images_per_row + 1, i * (max_images_per_row + 1) + j + 2)\n",
    "            plt.imshow(right_image)\n",
    "            plt.title(f\"Right Image {start_idx + j + 1}\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to create and save the dataset if loading fails\n",
    "def create_and_save_combined_dataset():\n",
    "    train_valid_offical_dataset = create_train_valid_dataset(True,'gaussian','salt_and_pepper', 20)\n",
    "    train_valid_outside_dataset = create_train_valid_dataset_archive(True,'gaussian','salt_and_pepper', 20)\n",
    "    train_valid_dataset = train_valid_offical_dataset + train_valid_outside_dataset\n",
    "\n",
    "    # Save data\n",
    "    joblib.dump(train_valid_dataset, 'D:/cv_data/train_valid_dataset.joblib')\n",
    "\n",
    "# Try to load the dataset\n",
    "try:\n",
    "    train_valid_dataset = joblib.load('D:/cv_data/train_valid_dataset.joblib')\n",
    "    print(f\"Loaded dataset size is {len(train_valid_dataset)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset not found, creating and saving...\")\n",
    "    create_and_save_combined_dataset()\n",
    "    train_valid_dataset = joblib.load('D:/cv_data/train_valid_dataset.joblib')\n",
    "    print(f\"Created and saved dataset size is {len(train_valid_dataset)}\")\n",
    "\n",
    "# Now you have the dataset loaded or created, and you can work with it as needed.\n",
    "print(train_valid_dataset[6000][0].shape)\n",
    "display_image_pair(train_valid_dataset[6000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# SIFT and FLANN\n",
    "def detect_and_compute_sift_features(img):\n",
    "    \"\"\"Detect and compute SIFT interest points and their descriptors.\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray, None)\n",
    "    return kp, des\n",
    "\n",
    "def match_features_with_flann(des1, des2):\n",
    "    \"\"\"Match features using FLANN matcher.\"\"\"\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    search_params = dict(checks=50)  # or pass empty dictionary\n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "    matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Need to draw only good matches, so create a mask\n",
    "    matches_mask = [[0, 0] for _ in range(len(matches))]\n",
    "\n",
    "    # ratio test as per Lowe's paper\n",
    "    for i, (m, n) in enumerate(matches):\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            matches_mask[i] = [1, 0]\n",
    "\n",
    "    return matches, matches_mask\n",
    "\n",
    "def draw_image_matches(img1, kp1, img2, kp2, matches, matches_mask):\n",
    "    \"\"\"Draw matches of two images.\"\"\"\n",
    "    draw_params = dict(matchColor=(0, 255, 0),\n",
    "                       singlePointColor=(255, 0, 0),\n",
    "                       matchesMask=matches_mask,\n",
    "                       flags=cv2.DrawMatchesFlags_DEFAULT)\n",
    "\n",
    "    img_matches = cv2.drawMatchesKnn(img1, kp1, img2, kp2, matches, None, **draw_params)\n",
    "    plt.imshow(img_matches)\n",
    "    plt.show()\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.cvtColor(cv2.imread('image1.jpg'), cv2.COLOR_BGR2RGB)\n",
    "img2 = cv2.cvtColor(cv2.imread('image2.jpg'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Detect and compute SIFT features\n",
    "kp1, des1 = detect_and_compute_sift_features(img1)\n",
    "kp2, des2 = detect_and_compute_sift_features(img2)\n",
    "\n",
    "# Match features using FLANN\n",
    "matches, matches_mask = match_features_with_flann(des1, des2)\n",
    "\n",
    "# Draw matches\n",
    "draw_image_matches(img1, kp1, img2, kp2, matches, matches_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the model\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the feature extraction model\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=base_model.get_layer('block5_pool').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(image, model=feature_extractor):\n",
    "    # Convert the image pixels to a numpy array\n",
    "    image = img_to_array(image)\n",
    "    # Reshape data for the model\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    # Prepare the image for the VGG model\n",
    "    image = preprocess_input(image)\n",
    "    # Get features\n",
    "    feature = model.predict(image, use_multiprocessing=True)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the distance to calculate the simimalirty\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def calculate_cosine_distance(left_image, right_image, model):\n",
    "    left_features = extract_image_features(left_image, model)\n",
    "    right_features = extract_image_features(right_image, model)\n",
    "    return cosine_similarity([left_features.flatten()], [right_features.flatten()])[0][0]\n",
    "\n",
    "def calculate_euclidean_distance(left_image, right_image, model):\n",
    "    left_features = extract_image_features(left_image, model)\n",
    "    right_features = extract_image_features(right_image, model)\n",
    "    return distance.euclidean([left_features.flatten()], [right_features.flatten()])\n",
    "\n",
    "def calculate_manhattan_distance(left_image, right_image, model):\n",
    "    left_features = extract_image_features(left_image, model)\n",
    "    right_features = extract_image_features(right_image, model)\n",
    "    return distance.cityblock([left_features.flatten()], [right_features.flatten()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets (e.g., 80% for training, 20% for validation)\n",
    "train_pairs, valid_pairs = train_test_split(train_valid_dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "def data_generator(pair_list, batch_size=32, num_right_images=20):\n",
    "    while True:\n",
    "        left_images = []\n",
    "        right_images = []\n",
    "        labels = []\n",
    "\n",
    "        # Shuffle the pairs for each epoch\n",
    "        random.shuffle(pair_list)\n",
    "\n",
    "        for pair in pair_list:\n",
    "            left_image, right_images_list = pair[0], pair[1]\n",
    "\n",
    "            # Create labels as a list of similarity scores (1.0 for the similar image, 0.0 for dissimilar images)\n",
    "            label = [1] + [0] * (num_right_images - 1)\n",
    "\n",
    "            left_images.append(left_image)  # Add the left image to the left_images list\n",
    "            right_images.append(right_images_list[:num_right_images])\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(left_images) >= batch_size:\n",
    "                yield [np.array(left_images), np.array(right_images)], np.array(labels)\n",
    "                left_images = []\n",
    "                right_images = []\n",
    "                labels = []\n",
    "\n",
    "        # Yield the remaining data in the last batch\n",
    "        if len(left_images) > 0:\n",
    "            yield [np.array(left_images), np.array(right_images)], np.array(labels)\n",
    "\n",
    "left_image = train_pairs[30][0]\n",
    "right_image = train_pairs[30][1][0]\n",
    "\n",
    "draw_image_matches(sift, [left_image,right_image])\n",
    "print(f\"training size is {len(train_pairs)}\")\n",
    "print(f\"VGG16 cosine score is {calculate_cosine_distance(left_image,right_image,base_model)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
